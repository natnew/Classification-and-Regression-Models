{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week_9_Python_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natnew/Classification-and-Regression-Models/blob/main/week_9_Python_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67X-QXEB0AKB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bsYiMjn3Vht"
      },
      "source": [
        "#Load IRIS Dataset\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most fundamental form of regression model is univariate linear regression, where a model is built \n",
        "using a single independent variable which has a linear relationship with the dependent. In Python, \n",
        "sklearn machine learning library has the linear_model module that contains linear regression function. \n",
        "First, load in the “iris” dataset. Once that has been loaded, use only Petal length to predict Petal Width. \n",
        "The LinearRegression() construct a basic linear model of the relationship between the features “petal \n",
        "length” and “petal width”. We first slice the “petal length” and “petal width” columns into irisX and irisY\n",
        "variables. Use the following command:"
      ],
      "metadata": {
        "id": "ZkhqNulrSWNe"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tKcK3wn3G9u"
      },
      "source": [
        "# Use only one feature\n",
        "#'feature_names': ['sepal length (cm)',   'sepal width (cm)',  'petal length (cm)',  'petal width (cm)'],\n",
        "\n",
        "irisX = iris.data[:, 3] #2 represent petal length\n",
        "irisX = irisX.reshape(-1,1)\n",
        "irisY = iris.data[:, 2] #3 represent petal width\n",
        "irisY = irisY.reshape(-1,1)\n",
        "# Variables\n",
        "#irisX= iris_df.drop(labels= 'sepal length (cm)', axis= 1)\n",
        "#irisY= iris_df['sepal length (cm)']\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZENTjUsdRu3Y"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "irisX_train = irisX[:-30]\n",
        "irisX_test = irisX[-30:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "irisY_train = irisY[:-30]\n",
        "irisY_test = irisY[-30:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPhVc92p1BcC"
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5G6pqIZ1XAB",
        "outputId": "e9457b09-c1a6-42ef-aa85-1a78529f47dd"
      },
      "source": [
        "# Train the model using the training sets\n",
        "regr.fit(irisX_train, irisY_train)\n",
        "regr.fit(irisX, irisY)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9MY_KZL17vY"
      },
      "source": [
        "# Make predictions using the testing set\n",
        "predictY = regr.predict(irisX_test)\n",
        "predictY = regr.predict(irisX)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model has been created and trained, we can look at the coefficient values that have been \n",
        "generated. Use the lrMode.coef_ and lrMode.intercept_ to print this information to the console:"
      ],
      "metadata": {
        "id": "lDBUZ2QxTHL2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkuRHyjd2Env",
        "outputId": "fd5380fb-e280-4e85-a876-c68f1f172b68"
      },
      "source": [
        "'''\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f' % mean_squared_error(irisY_test, predictY))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination: %.2f' % r2_score(irisY_test, predictY))\n",
        "'''\n",
        "##############################\n",
        "# The coefficients\n",
        "print('Coefficients: ', regr.coef_)\n",
        "print('Intercept: ', regr.intercept_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f' % mean_squared_error(irisY, predictY))\n",
        "# The Adjusted R squared error\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination / Adjusted R squared: %.2f' % r2_score(irisY, predictY))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients:  [[2.2299405]]\n",
            "Intercept:  [1.08355803]\n",
            "Mean squared error: 0.23\n",
            "Coefficient of determination / Adjusted R squared: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the values for the intercept and the coefficient for “petal width”, i.e. the x value. If you \n",
        "were to transpose these values into the equation for the line of best fit, you should get:\n",
        "> y = 2.2x + 1.08"
      ],
      "metadata": {
        "id": "cEVoGu1lUBra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This equation therefore describes the relationship between the two features, in linear terms. Use the \n",
        "linear regression model to predict the “petal length” by providing the “petal width” as input.\n",
        ">predictY = lrModel.predict(irisX)\n"
      ],
      "metadata": {
        "id": "rzczmWYOUJ_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This equation therefore describes the relationship between the two features, in linear terms. Use the \n",
        "linear regression model to predict the “petal length” by providing the “petal width” as input.\n",
        "predictY = lrModel.predict(irisX)\n"
      ],
      "metadata": {
        "id": "FpeHFH7NURP9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUuqyk54PAqk",
        "outputId": "026cddab-13c2-4f98-e8be-f47661f4bbbf"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X2 = sm.add_constant(irisX)\n",
        "est = sm.OLS(irisY, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.927\n",
            "Model:                            OLS   Adj. R-squared:                  0.927\n",
            "Method:                 Least Squares   F-statistic:                     1882.\n",
            "Date:                Sun, 16 Jan 2022   Prob (F-statistic):           4.68e-86\n",
            "Time:                        05:20:23   Log-Likelihood:                -101.18\n",
            "No. Observations:                 150   AIC:                             206.4\n",
            "Df Residuals:                     148   BIC:                             212.4\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.0836      0.073     14.850      0.000       0.939       1.228\n",
            "x1             2.2299      0.051     43.387      0.000       2.128       2.332\n",
            "==============================================================================\n",
            "Omnibus:                        2.438   Durbin-Watson:                   1.430\n",
            "Prob(Omnibus):                  0.295   Jarque-Bera (JB):                1.966\n",
            "Skew:                           0.211   Prob(JB):                        0.374\n",
            "Kurtosis:                       3.369   Cond. No.                         3.70\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that the model has produced the correct findings, first plot the data onto a scatter plot, and \n",
        "then map the regression line onto the plot. Use the following commands:\n",
        "\n"
      ],
      "metadata": {
        "id": "eNIUwgVhUeIS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "WBEKyVa31biY",
        "outputId": "1715c609-a17d-4575-b5ab-d5f01718826a"
      },
      "source": [
        "# Plot outputs\n",
        "plt.scatter(irisX_test, irisY_test,  color='black')\n",
        "plt.plot(irisX_test, predictY, color='blue', linewidth=2)\n",
        "plt.title('Linear Regression - Iris dataset')\n",
        "plt.xlabel('sepal length (cm) - X')\n",
        "plt.ylabel('sepal width (cm) - y')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-020bfcd8d318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirisX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirisY_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mirisX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Linear Regression - Iris dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sepal length (cm) - X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30, 1) and (150, 1)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_uKX6Zg2hHq"
      },
      "source": [
        "#print(np.c_[irisX_test,irisY_test])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BaLwQpkZHkni",
        "outputId": "703d5436-25e9-44a2-b271-ef2fe5f23a4c"
      },
      "source": [
        "# Plot outputs\n",
        "plt.scatter(irisX, irisY,  color='black')\n",
        "plt.plot(irisX, predictY, color='blue', linewidth=2)\n",
        "plt.title('Linear Regression - Iris dataset')\n",
        "plt.xlabel('Petal Width (cm) - X')\n",
        "plt.ylabel('Petal Length (cm) - y')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see that the steepness of the slope and the value of the intercept correspond with the \n",
        "output of the model. Before we can make any predictions using the model, however, we must check the \n",
        "model fit, to ensure that the predictive capacity of the model is sufficient to make reliable predictions. \n",
        "To do this, use the statmodels library to print the details of the model to the console. Use the following \n",
        "command:\n"
      ],
      "metadata": {
        "id": "ZCqNLeKxVjSY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7wQ9hUiQqvL"
      },
      "source": [
        "# Diamonds Dataset linear regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download Diamonds.csv file\n",
        "!pip install gdown\n",
        "!gdown --id 12Ck2ZZEgauUqTdYPTk0HhCDho6HSN6y8"
      ],
      "metadata": {
        "id": "ZvSWEDpIheuk",
        "outputId": "8c6cd740-3a58-4503-ccb9-2d5b5fd555af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12Ck2ZZEgauUqTdYPTk0HhCDho6HSN6y8\n",
            "To: /content/diamonds.csv\n",
            "100% 2.77M/2.77M [00:00<00:00, 79.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92OKzM0-QwgY",
        "outputId": "58b25d03-56d3-4cc9-f34f-53824cf689ed"
      },
      "source": [
        "import pandas as pd\n",
        "diamonds = pd.read_csv('/content/diamonds.csv')\n",
        "print(diamonds.shape)\n",
        "print(diamonds.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53940, 10)\n",
            "   carat      cut color clarity  depth  table  price     x     y     z\n",
            "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
            "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
            "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
            "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
            "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbN1Y1tHRH_Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the targets into training/testing sets\n",
        "trainset , testset   = train_test_split(diamonds, train_size=0.8, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3kPTTF-SJQq"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "lrModel = linear_model.LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmT-IvNpSclh",
        "outputId": "3860bc9b-5a1a-439e-8a80-d32cec7b3ee1"
      },
      "source": [
        "carat = trainset[['carat']]\n",
        "price = trainset[['price']]\n",
        "lrModel.fit(carat,price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98tm_L11Tqbh",
        "outputId": "5e30cefa-70c6-4ecd-c2b1-a1e3d4ffbcc7"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X2 = sm.add_constant(carat)\n",
        "est = sm.OLS(price, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.850\n",
            "Model:                            OLS   Adj. R-squared:                  0.850\n",
            "Method:                 Least Squares   F-statistic:                 2.437e+05\n",
            "Date:                Thu, 09 Dec 2021   Prob (F-statistic):               0.00\n",
            "Time:                        14:05:09   Log-Likelihood:            -3.7827e+05\n",
            "No. Observations:               43152   AIC:                         7.566e+05\n",
            "Df Residuals:                   43150   BIC:                         7.566e+05\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const      -2248.1731     14.578   -154.218      0.000   -2276.746   -2219.600\n",
            "carat       7753.2711     15.705    493.690      0.000    7722.490    7784.053\n",
            "==============================================================================\n",
            "Omnibus:                    11279.497   Durbin-Watson:                   2.010\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           128402.604\n",
            "Skew:                           0.933   Prob(JB):                         0.00\n",
            "Kurtosis:                      11.242   Cond. No.                         3.64\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GWJkYUUwpP"
      },
      "source": [
        "testCarat = testset[['carat']]#.values.reshape(-1,1)\n",
        "price_pred = lrModel.predict(testCarat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "uLN7ZOYDV0e-",
        "outputId": "f26a63ec-52b6-4cdc-88b8-45240ec7ac05"
      },
      "source": [
        "import pandas as pd\n",
        "#carat_price = diamonds[[\"carat\", \"price\"]]\n",
        "#corr = carat_price.corr(method='pearson')\n",
        "#corr\n",
        "\n",
        "df = pd.DataFrame(data=price_pred,columns=['predPrice'])\n",
        "df2 = df.merge(testset[['price']],left_index=True, right_index=True)\n",
        "corr = df2.corr(method='pearson')\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predPrice</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predPrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>0.006598</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           predPrice     price\n",
              "predPrice   1.000000  0.006598\n",
              "price       0.006598  1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNhEuSAJwTGu",
        "outputId": "4862fbf1-a410-4fbc-ad2a-38b2fe05cfc8"
      },
      "source": [
        "#If you want to predict your own datapoint\n",
        "newValue = np.array([[0.23]])\n",
        "#newValue.reshape(1,-1)\n",
        "tmpPrice = lrModel.predict(newValue)\n",
        "tmpPrice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-464.92071797]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqL9mpVzxpKe"
      },
      "source": [
        "# Multi-variable regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download Diamonds.csv file\n",
        "!pip install gdown\n",
        "!gdown --id 12Ck2ZZEgauUqTdYPTk0HhCDho6HSN6y8"
      ],
      "metadata": {
        "id": "dGJzSmfyhbSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t0IESnhxs3l",
        "outputId": "40cc62c1-ecd5-4adb-88c8-d03262e5da8c"
      },
      "source": [
        "import pandas as pd\n",
        "diamonds = pd.read_csv('/content/diamonds.csv')\n",
        "print(diamonds.shape)\n",
        "print(diamonds.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53940, 10)\n",
            "   carat      cut color clarity  depth  table  price     x     y     z\n",
            "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
            "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
            "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
            "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
            "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-xWp6_Ux6fP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "trainset , testset   = train_test_split(diamonds, train_size=0.8, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSC0wtrYx_rN"
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "lrModel = linear_model.LinearRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59e5mCkLyRR-"
      },
      "source": [
        "features = trainset[['carat','x','y','z']]#.values.reshape(-1,1)\n",
        "price = trainset[['price']]#.values.reshape(-1,1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzgHyTRHnxlF"
      },
      "source": [
        "Linear Regression Model with multiple variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUGXj1gLnw5o",
        "outputId": "fd23776c-bbf7-403b-a796-1da8fde487d9"
      },
      "source": [
        "lrModel.fit(features,price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVrT77_yy4Wc",
        "outputId": "e7c8c0fa-50db-45e8-f200-682103a44430"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X2 = sm.add_constant(features)\n",
        "est = sm.OLS(price, X2)\n",
        "est2 = est.fit()\n",
        "print(est2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.854\n",
            "Model:                            OLS   Adj. R-squared:                  0.854\n",
            "Method:                 Least Squares   F-statistic:                 6.304e+04\n",
            "Date:                Thu, 09 Dec 2021   Prob (F-statistic):               0.00\n",
            "Time:                        14:08:53   Log-Likelihood:            -3.7765e+05\n",
            "No. Observations:               43152   AIC:                         7.553e+05\n",
            "Df Residuals:                   43147   BIC:                         7.554e+05\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1718.1459    115.702     14.850      0.000    1491.368    1944.924\n",
            "carat        1.01e+04     69.701    144.929      0.000    9964.998    1.02e+04\n",
            "x           -859.2422     43.057    -19.956      0.000    -943.635    -774.849\n",
            "y            129.4394     26.089      4.961      0.000      78.305     180.574\n",
            "z           -468.9301     41.508    -11.297      0.000    -550.286    -387.574\n",
            "==============================================================================\n",
            "Omnibus:                    11458.092   Durbin-Watson:                   2.011\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           267964.148\n",
            "Skew:                           0.735   Prob(JB):                         0.00\n",
            "Kurtosis:                      15.119   Cond. No.                         169.\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Fl43_nNMtE"
      },
      "source": [
        "# Feature Selection : Check importance of a feature using Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6izBxlLNQ3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ecbd9b-9f3d-47aa-c580-8464f59ac752"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipeline = Pipeline([\n",
        "                     ('scaler',StandardScaler()),\n",
        "                     ('model',linear_model.Lasso())\n",
        "])\n",
        "\n",
        "reg = GridSearchCV(pipeline,\n",
        "                      {'model__alpha':np.arange(0.1,10,0.1)},\n",
        "                      cv = 5, scoring=\"neg_mean_squared_error\",verbose=3\n",
        "                      )\n",
        "reg.fit(features,price)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n",
            "[CV 1/5] END ...........model__alpha=0.1;, score=-2212203.927 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=0.1;, score=-2452301.859 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.1;, score=-2387420.078 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.1;, score=-2399860.621 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.1;, score=-2391018.284 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.2;, score=-2212374.382 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.2;, score=-2450260.076 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.2;, score=-2387491.456 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.2;, score=-2399420.575 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.2;, score=-2391054.738 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=0.30000000000000004;, score=-2212546.183 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=0.30000000000000004;, score=-2448265.419 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=0.30000000000000004;, score=-2387564.404 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=0.30000000000000004;, score=-2398917.394 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=0.30000000000000004;, score=-2391093.444 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.4;, score=-2212719.117 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.4;, score=-2446320.478 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.4;, score=-2387639.057 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.4;, score=-2398421.364 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.4;, score=-2391134.308 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.5;, score=-2212893.975 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.5;, score=-2444424.582 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.5;, score=-2387715.096 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.5;, score=-2397927.897 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.5;, score=-2391177.370 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.6;, score=-2213069.962 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.6;, score=-2442578.160 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.6;, score=-2387792.848 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.6;, score=-2397436.789 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.6;, score=-2391222.716 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=0.7000000000000001;, score=-2213247.762 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=0.7000000000000001;, score=-2440779.621 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=0.7000000000000001;, score=-2387872.342 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=0.7000000000000001;, score=-2396947.812 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=0.7000000000000001;, score=-2391270.209 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.8;, score=-2213426.198 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.8;, score=-2439030.208 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.8;, score=-2387953.614 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.8;, score=-2396468.549 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.8;, score=-2391319.772 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=0.9;, score=-2213606.232 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=0.9;, score=-2437325.970 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=0.9;, score=-2388036.206 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=0.9;, score=-2395992.881 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=0.9;, score=-2391371.794 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=1.0;, score=-2213787.890 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=1.0;, score=-2435672.531 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=1.0;, score=-2388120.495 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=1.0;, score=-2395520.770 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=1.0;, score=-2391425.839 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=1.1;, score=-2213971.198 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=1.1;, score=-2434071.136 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=1.1;, score=-2388205.884 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=1.1;, score=-2395052.179 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=1.1;, score=-2391482.125 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=1.2000000000000002;, score=-2214156.187 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.2000000000000002;, score=-2432516.518 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.2000000000000002;, score=-2388293.531 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=1.2000000000000002;, score=-2394587.066 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.2000000000000002;, score=-2391540.663 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=1.3000000000000003;, score=-2214340.832 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.3000000000000003;, score=-2431008.735 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.3000000000000003;, score=-2388382.919 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=1.3000000000000003;, score=-2394125.390 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.3000000000000003;, score=-2391601.464 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=1.4000000000000001;, score=-2214529.048 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.4000000000000001;, score=-2429547.859 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.4000000000000001;, score=-2388473.217 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=1.4000000000000001;, score=-2393667.106 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.4000000000000001;, score=-2391664.037 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=1.5000000000000002;, score=-2214716.623 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.5000000000000002;, score=-2428141.205 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.5000000000000002;, score=-2388566.038 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=1.5000000000000002;, score=-2393212.168 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.5000000000000002;, score=-2391729.332 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=1.6;, score=-2214908.139 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=1.6;, score=-2426774.737 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=1.6;, score=-2388659.621 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=1.6;, score=-2392773.824 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=1.6;, score=-2391796.927 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=1.7000000000000002;, score=-2215098.668 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.7000000000000002;, score=-2425463.190 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.7000000000000002;, score=-2388755.933 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=1.7000000000000002;, score=-2392326.385 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.7000000000000002;, score=-2391866.120 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=1.8000000000000003;, score=-2215290.619 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=1.8000000000000003;, score=-2424199.429 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.8000000000000003;, score=-2388852.825 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=1.8000000000000003;, score=-2391896.483 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.8000000000000003;, score=-2391938.262 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=1.9000000000000001;, score=-2215483.993 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=1.9000000000000001;, score=-2422983.557 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=1.9000000000000001;, score=-2388951.342 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=1.9000000000000001;, score=-2391456.489 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=1.9000000000000001;, score=-2392011.870 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=2.0;, score=-2215682.018 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=2.0;, score=-2421815.683 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=2.0;, score=-2389052.930 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=2.0;, score=-2391035.025 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=2.0;, score=-2392087.657 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=2.1;, score=-2215878.385 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=2.1;, score=-2420695.922 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=2.1;, score=-2389154.796 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=2.1;, score=-2390602.417 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=2.1;, score=-2392166.629 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=2.2;, score=-2216076.181 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=2.2;, score=-2419624.394 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=2.2;, score=-2389258.297 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=2.2;, score=-2390189.389 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=2.2;, score=-2392246.843 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=2.3000000000000003;, score=-2216275.404 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=2.3000000000000003;, score=-2418601.223 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=2.3000000000000003;, score=-2389363.435 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=2.3000000000000003;, score=-2389764.107 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=2.3000000000000003;, score=-2392329.237 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=2.4000000000000004;, score=-2216476.055 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=2.4000000000000004;, score=-2417634.633 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=2.4000000000000004;, score=-2389470.214 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=2.4000000000000004;, score=-2389359.511 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=2.4000000000000004;, score=-2392415.096 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=2.5000000000000004;, score=-2216678.133 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=2.5000000000000004;, score=-2416708.525 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=2.5000000000000004;, score=-2389578.634 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=2.5000000000000004;, score=-2388959.156 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=2.5000000000000004;, score=-2392501.925 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=2.6;, score=-2216886.154 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=2.6;, score=-2415831.119 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=2.6;, score=-2389688.699 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=2.6;, score=-2388545.326 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=2.6;, score=-2392590.931 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=2.7;, score=-2217091.295 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=2.7;, score=-2415002.539 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=2.7;, score=-2389802.843 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=2.7;, score=-2388153.400 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=2.7;, score=-2392682.112 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=2.8000000000000003;, score=-2217297.872 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=2.8000000000000003;, score=-2414222.901 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=2.8000000000000003;, score=-2389916.368 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=2.8000000000000003;, score=-2387765.713 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=2.8000000000000003;, score=-2392777.187 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=2.9000000000000004;, score=-2217505.887 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=2.9000000000000004;, score=-2413492.312 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=2.9000000000000004;, score=-2390031.559 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=2.9000000000000004;, score=-2387363.264 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=2.9000000000000004;, score=-2392872.805 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=3.0000000000000004;, score=-2217715.341 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=3.0000000000000004;, score=-2412810.867 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.0000000000000004;, score=-2390148.421 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.0000000000000004;, score=-2386984.003 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.0000000000000004;, score=-2392970.591 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=3.1;, score=-2217926.235 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=3.1;, score=-2412178.643 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=3.1;, score=-2390266.957 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=3.1;, score=-2386608.980 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=3.1;, score=-2393070.540 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=3.2;, score=-2218138.570 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=3.2;, score=-2411588.993 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=3.2;, score=-2390387.176 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=3.2;, score=-2386238.198 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=3.2;, score=-2393172.647 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=3.3000000000000003;, score=-2218352.349 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=3.3000000000000003;, score=-2411049.269 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.3000000000000003;, score=-2390509.081 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.3000000000000003;, score=-2385851.238 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.3000000000000003;, score=-2393279.290 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=3.4000000000000004;, score=-2218567.573 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=3.4000000000000004;, score=-2410565.770 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.4000000000000004;, score=-2390628.880 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.4000000000000004;, score=-2385488.876 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.4000000000000004;, score=-2393385.820 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=3.5000000000000004;, score=-2218784.247 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=3.5000000000000004;, score=-2410120.189 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.5000000000000004;, score=-2390753.930 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.5000000000000004;, score=-2385130.754 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.5000000000000004;, score=-2393494.496 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=3.6;, score=-2219002.374 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=3.6;, score=-2409730.995 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=3.6;, score=-2390880.675 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=3.6;, score=-2384776.871 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=3.6;, score=-2393605.311 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=3.7;, score=-2219221.959 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=3.7;, score=-2409387.132 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=3.7;, score=-2391009.121 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=3.7;, score=-2384427.227 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=3.7;, score=-2393718.258 total time=   0.0s\n",
            "[CV 1/5] END model__alpha=3.8000000000000003;, score=-2219435.167 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=3.8000000000000003;, score=-2409085.472 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.8000000000000003;, score=-2391139.279 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.8000000000000003;, score=-2384059.848 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.8000000000000003;, score=-2393833.329 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=3.9000000000000004;, score=-2219657.296 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=3.9000000000000004;, score=-2408837.166 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=3.9000000000000004;, score=-2391271.159 total time=   0.1s\n",
            "[CV 4/5] END model__alpha=3.9000000000000004;, score=-2383718.621 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=3.9000000000000004;, score=-2393950.516 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=4.0;, score=-2219880.878 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=4.0;, score=-2408617.379 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.0;, score=-2391404.408 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.0;, score=-2383381.634 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.0;, score=-2394069.812 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=4.1;, score=-2220105.922 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=4.1;, score=-2408473.873 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.1;, score=-2391537.556 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=4.1;, score=-2383047.988 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.1;, score=-2394191.207 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.2;, score=-2220332.437 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=4.2;, score=-2408407.313 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=4.2;, score=-2391671.189 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.2;, score=-2382716.165 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.2;, score=-2394314.569 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.3;, score=-2220560.433 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=4.3;, score=-2408379.795 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.3;, score=-2391742.698 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=4.3;, score=-2382386.633 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.3;, score=-2394443.603 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=4.3999999999999995;, score=-2220788.621 total time=   0.0s\n",
            "[CV 2/5] END model__alpha=4.3999999999999995;, score=-2408389.981 total time=   0.0s\n",
            "[CV 3/5] END model__alpha=4.3999999999999995;, score=-2391815.755 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=4.3999999999999995;, score=-2382059.186 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=4.3999999999999995;, score=-2394570.105 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.5;, score=-2221009.674 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=4.5;, score=-2408436.426 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=4.5;, score=-2391896.665 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.5;, score=-2381733.455 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.5;, score=-2394697.650 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.6;, score=-2221203.371 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=4.6;, score=-2408516.599 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.6;, score=-2391972.828 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=4.6;, score=-2381433.183 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.6;, score=-2394825.737 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.7;, score=-2221384.040 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=4.7;, score=-2408610.496 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.7;, score=-2392050.537 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.7;, score=-2381109.871 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.7;, score=-2394958.479 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=4.8;, score=-2221577.115 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=4.8;, score=-2408563.831 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.8;, score=-2392129.792 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.8;, score=-2380786.182 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.8;, score=-2395084.850 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=4.9;, score=-2221760.475 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=4.9;, score=-2408533.693 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=4.9;, score=-2392217.486 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=4.9;, score=-2380486.480 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=4.9;, score=-2395203.442 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.0;, score=-2221945.199 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.0;, score=-2408506.727 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=5.0;, score=-2392299.842 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=5.0;, score=-2380184.277 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.0;, score=-2395306.803 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.1;, score=-2222143.161 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.1;, score=-2408479.798 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.1;, score=-2392383.743 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.1;, score=-2379877.364 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.1;, score=-2395416.185 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.2;, score=-2222330.568 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.2;, score=-2408454.273 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.2;, score=-2392476.705 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.2;, score=-2379561.797 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.2;, score=-2395522.185 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.3;, score=-2222519.338 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=5.3;, score=-2408430.154 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.3;, score=-2392563.702 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.3;, score=-2379229.797 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.3;, score=-2395630.038 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.4;, score=-2222722.236 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=5.4;, score=-2408409.174 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=5.4;, score=-2392652.243 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=5.4;, score=-2378920.553 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.4;, score=-2395745.539 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.5;, score=-2222913.681 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.5;, score=-2408387.924 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=5.5;, score=-2392750.518 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=5.5;, score=-2378503.945 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.5;, score=-2395857.100 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=5.6;, score=-2223106.488 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.6;, score=-2408368.077 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.6;, score=-2392842.151 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.6;, score=-2377400.426 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.6;, score=-2395970.511 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.7;, score=-2223300.656 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=5.7;, score=-2408351.641 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=5.7;, score=-2392935.325 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=5.7;, score=-2377240.837 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.7;, score=-2396092.165 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=5.8;, score=-2223509.844 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=5.8;, score=-2408334.664 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.8;, score=-2393030.041 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.8;, score=-2377083.417 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.8;, score=-2396209.275 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=5.9;, score=-2223706.678 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=5.9;, score=-2408319.089 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=5.9;, score=-2393135.221 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=5.9;, score=-2376928.166 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=5.9;, score=-2396328.234 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.0;, score=-2223904.873 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.0;, score=-2408304.916 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.0;, score=-2393233.021 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=6.0;, score=-2376775.085 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.0;, score=-2396449.041 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.1;, score=-2224119.090 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.1;, score=-2408294.519 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.1;, score=-2393332.361 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=6.1;, score=-2376624.172 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.1;, score=-2396578.725 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.2;, score=-2224319.941 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.2;, score=-2408283.214 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=6.2;, score=-2393433.242 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=6.2;, score=-2376475.429 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.2;, score=-2396703.219 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.3;, score=-2224522.150 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.3;, score=-2408273.310 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.3;, score=-2393545.367 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=6.3;, score=-2376328.855 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.3;, score=-2396829.559 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=6.4;, score=-2224725.719 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=6.4;, score=-2408267.515 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.4;, score=-2393649.324 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.4;, score=-2376184.449 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.4;, score=-2396965.462 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.5;, score=-2224946.306 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.5;, score=-2408260.478 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.5;, score=-2393754.819 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.5;, score=-2376042.213 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.5;, score=-2397095.478 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=6.6;, score=-2225152.520 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.6;, score=-2408254.840 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.6;, score=-2393861.853 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.6;, score=-2375902.146 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.6;, score=-2397227.337 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=6.7;, score=-2225360.090 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.7;, score=-2408250.601 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.7;, score=-2393980.964 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.7;, score=-2375764.248 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.7;, score=-2397361.039 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=6.8;, score=-2225585.808 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.8;, score=-2408250.908 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.8;, score=-2394091.065 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.8;, score=-2375628.520 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.8;, score=-2397505.021 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=6.9;, score=-2225796.011 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=6.9;, score=-2408249.533 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=6.9;, score=-2394202.703 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=6.9;, score=-2375438.433 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=6.9;, score=-2397642.385 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=7.0;, score=-2226007.571 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=7.0;, score=-2408249.557 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=7.0;, score=-2394315.877 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=7.0;, score=-2375307.151 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.0;, score=-2397781.589 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=7.1;, score=-2226220.485 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.1;, score=-2408250.977 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.1;, score=-2394442.015 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=7.1;, score=-2375178.038 total time=   0.0s\n",
            "[CV 5/5] END ...........model__alpha=7.1;, score=-2397931.859 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=7.2;, score=-2226452.658 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.2;, score=-2408257.419 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.2;, score=-2394558.246 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=7.2;, score=-2375051.094 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.2;, score=-2398074.712 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=7.3;, score=-2226668.192 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.3;, score=-2408261.701 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.3;, score=-2394676.012 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=7.3;, score=-2374926.320 total time=   0.0s\n",
            "[CV 5/5] END ...........model__alpha=7.3;, score=-2398219.401 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=7.4;, score=-2226885.080 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.4;, score=-2408267.379 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.4;, score=-2394795.312 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=7.4;, score=-2374803.714 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.4;, score=-2398365.926 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=7.5;, score=-2227103.321 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=7.5;, score=-2408274.453 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.5;, score=-2394928.520 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=7.5;, score=-2374683.278 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.5;, score=-2398524.325 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=7.6;, score=-2227341.984 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=7.6;, score=-2408287.063 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=7.6;, score=-2395050.867 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=7.6;, score=-2374565.011 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.6;, score=-2398674.482 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=7.7;, score=-2227562.829 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=7.7;, score=-2408296.995 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=7.7;, score=-2395174.745 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=7.7;, score=-2374448.913 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.7;, score=-2398826.472 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=7.8;, score=-2227785.027 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.8;, score=-2408308.321 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=7.8;, score=-2395300.156 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=7.8;, score=-2374334.985 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.8;, score=-2398991.230 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=7.9;, score=-2228008.576 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=7.9;, score=-2408321.041 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=7.9;, score=-2395440.477 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=7.9;, score=-2374223.225 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=7.9;, score=-2399146.836 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.0;, score=-2228253.763 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=8.0;, score=-2408339.855 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.0;, score=-2395568.921 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=8.0;, score=-2374113.635 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.0;, score=-2399304.271 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.1;, score=-2228479.900 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=8.1;, score=-2408355.429 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.1;, score=-2395698.896 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.1;, score=-2374006.214 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.1;, score=-2399463.536 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=8.2;, score=-2228707.386 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=8.2;, score=-2408372.395 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=8.2;, score=-2395830.399 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=8.2;, score=-2373900.962 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.2;, score=-2399636.467 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=8.3;, score=-2228936.222 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=8.3;, score=-2408390.753 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=8.3;, score=-2395977.876 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.3;, score=-2373797.879 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.3;, score=-2399799.326 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.4;, score=-2229187.967 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=8.4;, score=-2408415.807 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.4;, score=-2396112.401 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.4;, score=-2373696.965 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.4;, score=-2399964.011 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.5;, score=-2229419.372 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=8.5;, score=-2408437.013 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.5;, score=-2396248.452 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.5;, score=-2373598.221 total time=   0.0s\n",
            "[CV 5/5] END ...........model__alpha=8.5;, score=-2400130.522 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.6;, score=-2229652.125 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=8.6;, score=-2408459.610 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.6;, score=-2396386.031 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.6;, score=-2373501.646 total time=   0.0s\n",
            "[CV 5/5] END ...........model__alpha=8.6;, score=-2400311.637 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=8.7;, score=-2229886.224 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=8.7;, score=-2408483.597 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=8.7;, score=-2396540.707 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.7;, score=-2373407.240 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.7;, score=-2400481.718 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=8.8;, score=-2230144.561 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=8.8;, score=-2408514.930 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=8.8;, score=-2396681.290 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=8.8;, score=-2373315.003 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.8;, score=-2400653.622 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=8.9;, score=-2230381.210 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=8.9;, score=-2408541.759 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=8.9;, score=-2396823.399 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=8.9;, score=-2373224.935 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=8.9;, score=-2400827.347 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=9.0;, score=-2230619.204 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=9.0;, score=-2408569.977 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=9.0;, score=-2396967.031 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=9.0;, score=-2373080.792 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.0;, score=-2401016.653 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=9.1;, score=-2230858.542 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.1;, score=-2408599.582 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.1;, score=-2397128.949 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=9.1;, score=-2372995.177 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.1;, score=-2401193.924 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=9.2;, score=-2231123.498 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.2;, score=-2408630.575 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.2;, score=-2397275.570 total time=   0.1s\n",
            "[CV 4/5] END ...........model__alpha=9.2;, score=-2372911.732 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.2;, score=-2401373.012 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=9.3;, score=-2231365.365 total time=   0.1s\n",
            "[CV 2/5] END ...........model__alpha=9.3;, score=-2408669.673 total time=   0.1s\n",
            "[CV 3/5] END ...........model__alpha=9.3;, score=-2397423.712 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.3;, score=-2372830.456 total time=   0.0s\n",
            "[CV 5/5] END ...........model__alpha=9.3;, score=-2401568.807 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=9.4;, score=-2231608.574 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.4;, score=-2408703.500 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.4;, score=-2397573.376 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.4;, score=-2372751.349 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.4;, score=-2401751.418 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=9.5;, score=-2231853.125 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.5;, score=-2408738.713 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.5;, score=-2397742.577 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.5;, score=-2372674.411 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.5;, score=-2401935.841 total time=   0.1s\n",
            "[CV 1/5] END ...........model__alpha=9.6;, score=-2232124.728 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.6;, score=-2408775.311 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.6;, score=-2397895.211 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.6;, score=-2372599.643 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.6;, score=-2402122.078 total time=   0.1s\n",
            "[CV 1/5] END model__alpha=9.700000000000001;, score=-2232371.783 total time=   0.1s\n",
            "[CV 2/5] END model__alpha=9.700000000000001;, score=-2408820.760 total time=   0.1s\n",
            "[CV 3/5] END model__alpha=9.700000000000001;, score=-2398049.364 total time=   0.0s\n",
            "[CV 4/5] END model__alpha=9.700000000000001;, score=-2372527.044 total time=   0.1s\n",
            "[CV 5/5] END model__alpha=9.700000000000001;, score=-2402326.091 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=9.8;, score=-2232620.177 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.8;, score=-2408860.184 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.8;, score=-2398205.034 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.8;, score=-2372456.614 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.8;, score=-2402515.820 total time=   0.0s\n",
            "[CV 1/5] END ...........model__alpha=9.9;, score=-2232869.912 total time=   0.0s\n",
            "[CV 2/5] END ...........model__alpha=9.9;, score=-2408900.991 total time=   0.0s\n",
            "[CV 3/5] END ...........model__alpha=9.9;, score=-2398362.223 total time=   0.0s\n",
            "[CV 4/5] END ...........model__alpha=9.9;, score=-2372388.353 total time=   0.1s\n",
            "[CV 5/5] END ...........model__alpha=9.9;, score=-2402707.356 total time=   0.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                                       ('model', Lasso())]),\n",
              "             param_grid={'model__alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
              "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6,\n",
              "       2.7, 2.8, 2.9, 3. , 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9,\n",
              "       4. , 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5. , 5.1, 5.2,\n",
              "       5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6. , 6.1, 6.2, 6.3, 6.4, 6.5,\n",
              "       6.6, 6.7, 6.8, 6.9, 7. , 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8,\n",
              "       7.9, 8. , 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9, 9. , 9.1,\n",
              "       9.2, 9.3, 9.4, 9.5, 9.6, 9.7, 9.8, 9.9])},\n",
              "             scoring='neg_mean_squared_error', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJIgOB4Lj10E",
        "outputId": "6f593a1e-3d8c-4aa3-b739-816431f87bfc"
      },
      "source": [
        "##############################\n",
        "# The coefficients\n",
        "print('Best parameters: ', reg.best_params_)\n",
        "coefficients = reg.best_estimator_.named_steps['model'].coef_\n",
        "print('Coefficients: ', coefficients)\n",
        "\n",
        "importance = np.abs(coefficients)\n",
        "print(importance)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters:  {'model__alpha': 4.0}\n",
            "Coefficients:  [4646.84665338 -714.3673728    18.87113664 -299.59530487]\n",
            "[4646.84665338  714.3673728    18.87113664  299.59530487]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgyrY3QPfC9P"
      },
      "source": [
        "testFeatures = testset[['carat','x','y','z']]\n",
        "price_pred = lrModel.predict(testFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95kMdxEYfSxg",
        "outputId": "1c93c0dc-9140-4e16-b75b-a59851244fc7"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f' % mean_squared_error(testset[['price']], price_pred))\n",
        "# The Adjusted R squared error\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination / Adjusted R squared: %.2f' % r2_score(testset[['price']], price_pred))\n",
        "print(\"R2  : {}\".format(np.sqrt(r2_score(testset[['price']],price_pred))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 2257937.95\n",
            "Coefficient of determination / Adjusted R squared: 0.85\n",
            "R2  : 0.9244931766275668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ru0BpvVZ0Mqy",
        "outputId": "b67d33b6-7768-4417-e006-d981aac89e2e"
      },
      "source": [
        "df = pd.DataFrame(data=price_pred,columns=['predPrice'])\n",
        "df2 = df.merge(testset[['price']],left_index=True, right_index=True)\n",
        "corr = df2.corr(method='pearson')\n",
        "corr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predPrice</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>predPrice</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>0.008126</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           predPrice     price\n",
              "predPrice   1.000000  0.008126\n",
              "price       0.008126  1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyXnVhy6lXif"
      },
      "source": [
        "# Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHR72X_zlWqK",
        "outputId": "cfd9900a-5e98-468d-dacd-7aa8dd65294e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RFreg = RandomForestRegressor(n_estimators=73,\n",
        "                         min_samples_split=3,\n",
        "                         min_samples_leaf=20,\n",
        "                         max_depth=60)\n",
        "RFreg.fit(features,price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=60, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=20,\n",
              "                      min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=73, n_jobs=None, oob_score=False,\n",
              "                      random_state=None, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaC4czzSodpe"
      },
      "source": [
        "testFeatures = testset[['carat','x','y','z']]\n",
        "price_pred = RFreg.predict(testFeatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WXCxtFsoBln",
        "outputId": "334c7fcc-25b8-4dfd-dc3d-a072757abb72"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f' % mean_squared_error(testset[['price']], price_pred))\n",
        "# The Adjusted R squared error\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination / Adjusted R squared: %.2f' % r2_score(testset[['price']], price_pred))\n",
        "\n",
        "print(\"R2  : {}\".format(np.sqrt(r2_score(testset[['price']],price_pred))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean squared error: 1813618.06\n",
            "Coefficient of determination / Adjusted R squared: 0.88\n",
            "R2  : 0.9398310406252126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGvKmw0J1_bZ",
        "outputId": "2a78017c-c1e5-4d44-c533-e24ae8f13921"
      },
      "source": [
        "print('%.2f' % r2_score(testset[['price']], price_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8SVC2l3CeIX"
      },
      "source": [
        "# Selection of best parameters for Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpskTC0xCije",
        "outputId": "030d00a6-fd24-4a38-c132-caca20538e0b"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "n_estimators = [int(x) for x in np.linspace(10,200,10)]\n",
        "max_depth = [int(x) for x in np.linspace(10,100,10)]\n",
        "min_samples_split = [2,3,4,5,10]\n",
        "min_samples_leaf = [1,2,4,10,15,20]\n",
        "random_grid = {'n_estimators':n_estimators,'max_depth':max_depth,\n",
        "               'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf}\n",
        "RFrandom = RandomizedSearchCV(estimator=RFreg, param_distributions=random_grid,cv = 3)\n",
        "\n",
        "RFrandom.fit(features,price)\n",
        "y_pred = RFrandom.predict(testFeatures)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIvtcBNXDVgS",
        "outputId": "61eb62a6-c800-489b-c04f-42ca7a21ac28"
      },
      "source": [
        "rf_random.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 60,\n",
              " 'min_samples_leaf': 20,\n",
              " 'min_samples_split': 3,\n",
              " 'n_estimators': 73}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F8HldgzXtZl"
      },
      "source": [
        "# *Task - Boston Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "cQgZgTy6XwXX",
        "outputId": "75b2acd6-4b63-4cd3-a925-c1bc46c8f168"
      },
      "source": [
        "boston = datasets.load_boston()\n",
        "X = pd.DataFrame(data=boston.data,columns=boston.feature_names)\n",
        "y = pd.DataFrame(data=boston.target,columns=['price'])\n",
        "\n",
        "X['combined'] = X['TAX']+X['PTRATIO']\n",
        "\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>311.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>259.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>259.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>240.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>240.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>294.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>294.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>294.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>294.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1.0</td>\n",
              "      <td>273.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>294.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO       B  LSTAT  combined\n",
              "0    0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.90   4.98     311.3\n",
              "1    0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.90   9.14     259.8\n",
              "2    0.02729   0.0   7.07   0.0  0.469  ...  242.0     17.8  392.83   4.03     259.8\n",
              "3    0.03237   0.0   2.18   0.0  0.458  ...  222.0     18.7  394.63   2.94     240.7\n",
              "4    0.06905   0.0   2.18   0.0  0.458  ...  222.0     18.7  396.90   5.33     240.7\n",
              "..       ...   ...    ...   ...    ...  ...    ...      ...     ...    ...       ...\n",
              "501  0.06263   0.0  11.93   0.0  0.573  ...  273.0     21.0  391.99   9.67     294.0\n",
              "502  0.04527   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   9.08     294.0\n",
              "503  0.06076   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   5.64     294.0\n",
              "504  0.10959   0.0  11.93   0.0  0.573  ...  273.0     21.0  393.45   6.48     294.0\n",
              "505  0.04741   0.0  11.93   0.0  0.573  ...  273.0     21.0  396.90   7.88     294.0\n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}